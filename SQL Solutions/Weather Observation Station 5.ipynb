{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a37007a-ed09-4088-bc13-e98667df3388",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Query the two cities in STATION with the shortest and longest CITY names, as well as their respective lengths (i.e.: number of characters in the name). If there is more than one smallest or largest city, choose the one that comes first when ordered alphabetically.\n",
    "The STATION table is described as follows:\n",
    "\n",
    "\n",
    "![Output](https://s3.amazonaws.com/hr-challenge-images/9336/1449345840-5f0a551030-Station.jpg)\n",
    "\n",
    "\n",
    "where LAT_N is the northern latitude and LONG_W is the western longitude.\n",
    "\n",
    "Sample Input\n",
    "\n",
    "For example, CITY has four entries: DEF, ABC, PQRS and WXY.\n",
    "\n",
    "Sample Output\n",
    "\n",
    "ABC 3\n",
    "PQRS 4\n",
    "Explanation\n",
    "\n",
    "When ordered alphabetically, the CITY names are listed as ABC, DEF, PQRS, and WXY, with lengths  and . The longest name is PQRS, but there are  options for shortest named city. Choose ABC, because it comes first alphabetically.\n",
    "\n",
    "Note\n",
    "You can write two separate queries to get the desired output. It need not be a single query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7989bbe6-b0b8-460d-aade-b8ce16a6a8b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+-----+--------+----------+\n| ID|       City|State|   LAT_N|    LONG_W|\n+---+-----------+-----+--------+----------+\n|  1|   New York|   NY| 40.7128|   -74.006|\n|  2|Los Angeles|   CA| 34.0522| -118.2437|\n|  3|    Chicago|   IL| 41.8781|  -87.6298|\n|  4|    Houston|   TX| 29.7604|  -95.3698|\n|  5|    Phoenix|   AZ| 33.4484|  -112.074|\n|  6|San Antonio|   TX| 29.4241|  -98.4936|\n|  7|  San Diego|   CA| 32.7157| -117.1611|\n|  8|     Dallas|   TX| 32.7767|   -96.797|\n|  9|   San Jose|   CA| 37.3382| -121.8863|\n| 10|     Austin|   TX| 30.2672|  -97.7431|\n| 11|    Toronto|   ON|43.65107|-79.347015|\n| 12|     London|  ENG| 51.5074|   -0.1278|\n| 13|  Vancouver|   BC| 49.2827| -123.1207|\n| 14|     London|  ENG| 51.5074|   -0.1278|\n| 15|  Vancouver|   BC| 49.2827| -123.1207|\n+---+-----------+-----+--------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, FloatType\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"StationTable\").getOrCreate()\n",
    "\n",
    "# Define the schema for the STATION table\n",
    "schema = StructType([\n",
    "    StructField(\"ID\", IntegerType(), True),\n",
    "    StructField(\"City\", StringType(), True),\n",
    "    StructField(\"State\", StringType(), True),\n",
    "    StructField(\"LAT_N\", FloatType(), True),\n",
    "    StructField(\"LONG_W\", FloatType(), True)\n",
    "])\n",
    "\n",
    "# Create the sample data\n",
    "data = [\n",
    "    (1, \"New York\", \"NY\", 40.7128, -74.0060),\n",
    "    (2, \"Los Angeles\", \"CA\", 34.0522, -118.2437),\n",
    "    (3, \"Chicago\", \"IL\", 41.8781, -87.6298),\n",
    "    (4, \"Houston\", \"TX\", 29.7604, -95.3698),\n",
    "    (5, \"Phoenix\", \"AZ\", 33.4484, -112.0740),\n",
    "    (6, \"San Antonio\", \"TX\", 29.4241, -98.4936),\n",
    "    (7, \"San Diego\", \"CA\", 32.7157, -117.1611),\n",
    "    (8, \"Dallas\", \"TX\", 32.7767, -96.7970),\n",
    "    (9, \"San Jose\", \"CA\", 37.3382, -121.8863),\n",
    "    (10, \"Austin\", \"TX\", 30.2672, -97.7431),\n",
    "    (11, \"Toronto\", \"ON\", 43.65107, -79.347015),\n",
    "    (12, \"London\", \"ENG\", 51.5074, -0.1278),\n",
    "    (13, \"Vancouver\", \"BC\", 49.2827, -123.1207),\n",
    "    (14, \"London\", \"ENG\", 51.5074, -0.1278),\n",
    "    (15, \"Vancouver\", \"BC\", 49.2827, -123.1207)\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Save the DataFrame as a temporary table\n",
    "df.createOrReplaceTempView(\"STATION\")\n",
    "\n",
    "# Save as a permanent table (uncomment if needed)\n",
    "# df.write.mode(\"overwrite\").saveAsTable(\"STATION\")\n",
    "\n",
    "# Show the DataFrame\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad41ac02-b0a5-4896-82c9-b4f4c838181b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>CITY</th><th>NameLength</th></tr></thead><tbody><tr><td>Austin</td><td>6</td></tr><tr><td>Los Angeles</td><td>11</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "Austin",
         6
        ],
        [
         "Los Angeles",
         11
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "CITY",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "NameLength",
         "type": "\"integer\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%sql\n",
    "WITH CityLengths AS (\n",
    "    SELECT CITY, LENGTH(CITY) AS NameLength\n",
    "    FROM STATION\n",
    ")\n",
    "SELECT CITY, NameLength\n",
    "FROM (\n",
    "    SELECT CITY, NameLength,\n",
    "           ROW_NUMBER() OVER (ORDER BY CITY) AS rn\n",
    "    FROM CityLengths\n",
    "    WHERE NameLength = (SELECT MIN(NameLength) FROM CityLengths)\n",
    "    LIMIT 1\n",
    ") \n",
    "UNION ALL\n",
    "SELECT CITY, NameLength\n",
    "FROM (\n",
    "    SELECT CITY, NameLength,\n",
    "           ROW_NUMBER() OVER (ORDER BY CITY) AS rn\n",
    "    FROM CityLengths\n",
    "    WHERE NameLength = (SELECT MAX(NameLength) FROM CityLengths)\n",
    "    LIMIT 1\n",
    ")\n",
    "ORDER BY NameLength;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d52dd0ab-d68a-4853-89f0-dab703114bdb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+-----+-------+---------+---+\n| ID|       City|State|  LAT_N|   LONG_W|len|\n+---+-----------+-----+-------+---------+---+\n| 10|     Austin|   TX|30.2672| -97.7431|  6|\n|  2|Los Angeles|   CA|34.0522|-118.2437| 11|\n+---+-----------+-----+-------+---------+---+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, length, min, max\n",
    "\n",
    "# Add a column with the length of each city name\n",
    "df_with_len = df.withColumn(\"len\", length(col(\"City\")))\n",
    "\n",
    "# Get the minimum and maximum city name lengths\n",
    "min_len = df_with_len.agg(min(\"len\")).collect()[0][0]\n",
    "max_len = df_with_len.agg(max(\"len\")).collect()[0][0]\n",
    "\n",
    "# Find the shortest and longest city names, ordering alphabetically and picking the first\n",
    "shortest_city = df_with_len.filter(col(\"len\") == min_len).orderBy(\"City\").limit(1)\n",
    "longest_city = df_with_len.filter(col(\"len\") == max_len).orderBy(\"City\").limit(1)\n",
    "\n",
    "# Combine results\n",
    "shortest_city.union(longest_city).show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 946361087265122,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Weather Observation Station 5",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}